# Comparing `tmp/mdapy-0.8.5-cp39-cp39-win_amd64.whl.zip` & `tmp/mdapy-0.8.6-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,42 +1,42 @@
-Zip file size: 560581 bytes, number of entries: 40
--rw-rw-rw-  2.0 fat   121856 b- defN 23-Apr-09 10:34 _cluster_analysis.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   120832 b- defN 23-Apr-09 10:34 _neigh.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   205824 b- defN 23-Apr-09 10:34 _poly.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   329728 b- defN 23-Apr-09 10:34 _ptm.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   124928 b- defN 23-Apr-09 10:34 _rdf.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   191488 b- defN 23-Apr-09 10:34 _voronoi_analysis.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat     3552 b- defN 23-Apr-01 12:59 mdapy/__init__.py
+Zip file size: 472450 bytes, number of entries: 40
+-rw-rw-rw-  2.0 fat   108544 b- defN 23-Apr-22 09:26 _cluster_analysis.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   110080 b- defN 23-Apr-22 09:26 _neigh.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   316928 b- defN 23-Apr-22 09:26 _ptm.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   111616 b- defN 23-Apr-22 09:26 _rdf.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   202240 b- defN 23-Apr-22 09:26 _voronoi_analysis.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     3586 b- defN 23-Apr-12 15:04 mdapy/__init__.py
 -rw-rw-rw-  2.0 fat     7836 b- defN 23-Apr-01 12:38 mdapy/ackland_jones_analysis.py
 -rw-rw-rw-  2.0 fat    10839 b- defN 23-Jan-20 06:31 mdapy/calculator.py
--rw-rw-rw-  2.0 fat     7380 b- defN 23-Apr-01 12:39 mdapy/centro_symmetry_parameter.py
--rw-rw-rw-  2.0 fat     4432 b- defN 23-Apr-01 12:41 mdapy/cluser_analysis.py
+-rw-rw-rw-  2.0 fat     7816 b- defN 23-Apr-10 04:00 mdapy/centro_symmetry_parameter.py
+-rw-rw-rw-  2.0 fat     4431 b- defN 23-Apr-22 08:31 mdapy/cluser_analysis.py
 -rw-rw-rw-  2.0 fat    10198 b- defN 23-Apr-09 08:41 mdapy/common_neighbor_analysis.py
 -rw-rw-rw-  2.0 fat     6576 b- defN 23-Feb-22 06:10 mdapy/common_neighbor_parameter.py
--rw-rw-rw-  2.0 fat    26758 b- defN 23-Apr-01 12:53 mdapy/create_polycrystalline.py
+-rw-rw-rw-  2.0 fat    27216 b- defN 23-Apr-22 08:24 mdapy/create_polycrystalline.py
 -rw-rw-rw-  2.0 fat     5528 b- defN 23-Apr-01 13:00 mdapy/eam_average.py
 -rw-rw-rw-  2.0 fat    21039 b- defN 23-Jan-20 06:31 mdapy/eam_generate.py
 -rw-rw-rw-  2.0 fat     9960 b- defN 23-Jan-20 06:31 mdapy/entropy.py
 -rw-rw-rw-  2.0 fat    11015 b- defN 23-Apr-01 13:00 mdapy/identify_SFs_TBs.py
 -rw-rw-rw-  2.0 fat     6831 b- defN 23-Mar-11 08:28 mdapy/kdtree.py
 -rw-rw-rw-  2.0 fat    10077 b- defN 23-Apr-01 06:40 mdapy/lattice_maker.py
 -rw-rw-rw-  2.0 fat     8475 b- defN 23-Apr-01 13:02 mdapy/lindemann_parameter.py
 -rw-rw-rw-  2.0 fat     7154 b- defN 23-Apr-01 13:07 mdapy/mean_squared_displacement.py
 -rw-rw-rw-  2.0 fat    11369 b- defN 23-Apr-01 13:08 mdapy/neighbor.py
 -rw-rw-rw-  2.0 fat     9048 b- defN 23-Apr-01 13:09 mdapy/pair_distribution.py
 -rw-rw-rw-  2.0 fat     3082 b- defN 23-Jan-24 04:17 mdapy/plotset.py
 -rw-rw-rw-  2.0 fat     5227 b- defN 23-Apr-01 13:11 mdapy/polyhedral_template_matching.py
 -rw-rw-rw-  2.0 fat    11532 b- defN 23-Apr-01 13:12 mdapy/potential.py
+-rw-rw-rw-  2.0 fat     6995 b- defN 23-Apr-12 12:53 mdapy/replicate.py
 -rw-rw-rw-  2.0 fat    10755 b- defN 23-Apr-01 13:13 mdapy/spatial_binning.py
 -rw-rw-rw-  2.0 fat    28837 b- defN 23-Apr-01 13:14 mdapy/steinhardt_bond_orientation.py
--rw-rw-rw-  2.0 fat    73683 b- defN 23-Apr-06 13:42 mdapy/system.py
+-rw-rw-rw-  2.0 fat    76307 b- defN 23-Apr-22 08:50 mdapy/system.py
 -rw-rw-rw-  2.0 fat     7962 b- defN 23-Jan-20 06:31 mdapy/temperature.py
 -rw-rw-rw-  2.0 fat      562 b- defN 23-Jan-20 06:31 mdapy/timer.py
 -rw-rw-rw-  2.0 fat     9171 b- defN 23-Apr-01 13:16 mdapy/void_distribution.py
--rw-rw-rw-  2.0 fat     2965 b- defN 23-Apr-01 13:17 mdapy/voronoi_analysis.py
+-rw-rw-rw-  2.0 fat     3417 b- defN 23-Apr-22 08:53 mdapy/voronoi_analysis.py
 -rw-rw-rw-  2.0 fat     6650 b- defN 23-Apr-01 13:19 mdapy/warren_cowley_parameter.py
--rw-rw-rw-  2.0 fat     1594 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    10304 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       65 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     3272 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/RECORD
-40 files, 1448484 bytes uncompressed, 555467 bytes compressed:  61.7%
+-rw-rw-rw-  2.0 fat     1594 b- defN 23-Apr-22 09:26 mdapy-0.8.6.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    10571 b- defN 23-Apr-22 09:26 mdapy-0.8.6.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-22 09:26 mdapy-0.8.6.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       59 b- defN 23-Apr-22 09:26 mdapy-0.8.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     3264 b- defN 23-Apr-22 09:26 mdapy-0.8.6.dist-info/RECORD
+40 files, 1214487 bytes uncompressed, 467348 bytes compressed:  61.5%
```

## zipnote {}

```diff
@@ -1,16 +1,13 @@
 Filename: _cluster_analysis.cp39-win_amd64.pyd
 Comment: 
 
 Filename: _neigh.cp39-win_amd64.pyd
 Comment: 
 
-Filename: _poly.cp39-win_amd64.pyd
-Comment: 
-
 Filename: _ptm.cp39-win_amd64.pyd
 Comment: 
 
 Filename: _rdf.cp39-win_amd64.pyd
 Comment: 
 
 Filename: _voronoi_analysis.cp39-win_amd64.pyd
@@ -75,14 +72,17 @@
 
 Filename: mdapy/polyhedral_template_matching.py
 Comment: 
 
 Filename: mdapy/potential.py
 Comment: 
 
+Filename: mdapy/replicate.py
+Comment: 
+
 Filename: mdapy/spatial_binning.py
 Comment: 
 
 Filename: mdapy/steinhardt_bond_orientation.py
 Comment: 
 
 Filename: mdapy/system.py
@@ -99,23 +99,23 @@
 
 Filename: mdapy/voronoi_analysis.py
 Comment: 
 
 Filename: mdapy/warren_cowley_parameter.py
 Comment: 
 
-Filename: mdapy-0.8.5.dist-info/LICENSE
+Filename: mdapy-0.8.6.dist-info/LICENSE
 Comment: 
 
-Filename: mdapy-0.8.5.dist-info/METADATA
+Filename: mdapy-0.8.6.dist-info/METADATA
 Comment: 
 
-Filename: mdapy-0.8.5.dist-info/WHEEL
+Filename: mdapy-0.8.6.dist-info/WHEEL
 Comment: 
 
-Filename: mdapy-0.8.5.dist-info/top_level.txt
+Filename: mdapy-0.8.6.dist-info/top_level.txt
 Comment: 
 
-Filename: mdapy-0.8.5.dist-info/RECORD
+Filename: mdapy-0.8.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mdapy/__init__.py

```diff
@@ -1,12 +1,12 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 __author__ = "mushroomfire aka HerrWu"
-__version__ = "0.8.5"
+__version__ = "0.8.6"
 __license__ = "BSD License"
 
 from .ackland_jones_analysis import AcklandJonesAnalysis
 from .calculator import Calculator
 from .centro_symmetry_parameter import CentroSymmetryParameter
 from .cluser_analysis import ClusterAnalysis
 from .common_neighbor_analysis import CommonNeighborAnalysis
@@ -30,14 +30,15 @@
 from .steinhardt_bond_orientation import SteinhardtBondOrientation
 from .system import System, MultiSystem
 from .temperature import AtomicTemperature
 from .timer import timer
 from .void_distribution import VoidDistribution
 from .voronoi_analysis import VoronoiAnalysis
 from .warren_cowley_parameter import WarrenCowleyParameter
+from .replicate import Replicate
 
 
 def init(
     arch="cpu",
     cpu_max_num_threads=-1,
     offline_cache=False,
     debug=False,
```

## mdapy/centro_symmetry_parameter.py

```diff
@@ -4,14 +4,16 @@
 import taichi as ti
 import numpy as np
 if __name__ == "__main__":
     from kdtree import kdtree
 else:
     from .kdtree import kdtree
 
+vec3f32 = ti.types.vector(3, ti.f32)
+vec3f64 = ti.types.vector(3, ti.f64)
 
 @ti.data_oriented
 class CentroSymmetryParameter:
     """This class is used to compute the CentroSymmetry Parameter (CSP), 
     which is heluful to recgonize the structure in lattice, such as FCC and BCC.
     The  CSP is given by: 
     
@@ -62,31 +64,41 @@
         >>> CSP.csp # Check the csp value
     """
     def __init__(self, N, pos, box, boundary=[1,1,1], verlet_list=None):
         
         self.N = N
         self.pos = pos
         self.box = box
-        self.boundary = np.array(boundary)
+        self.boundary = ti.Vector([boundary[i] for i in range(3)], int)
+        if self.pos.dtype == np.float64:
+            self.box_length = vec3f64([box[i, 1] - box[i, 0] for i in range(3)])
+        elif self.pos.dtype == np.float32:
+            self.box_length = vec3f32([box[i, 1] - box[i, 0] for i in range(3)])
+        self.half_box_length = self.box_length / 2.0
         self.verlet_list = verlet_list
     
     @ti.func
-    def _pbc(self, rij, box:ti.types.ndarray(), boundary:ti.types.ndarray()):
-        for i in ti.static(range(3)):
-            if boundary[i] == 1:
-                box_length = box[i, 1] - box[i, 0]
-                rij[i] = rij[i] - box_length * ti.round(rij[i] / box_length)
+    def _pbc(self, rij):
+
+        for m in ti.static(range(3)):
+            if self.boundary[m]:
+                dx = rij[m]
+                x_size = self.box_length[m]
+                h_x_size = self.half_box_length[m]
+                if dx > h_x_size:
+                    dx = dx - x_size
+                if dx <= -h_x_size:
+                    dx = dx + x_size
+                rij[m] = dx
         return rij
 
     @ti.kernel
     def _get_csp(self, pair:ti.types.ndarray(), 
                   pos:ti.types.ndarray(dtype=ti.math.vec3), 
-                  verlet_list:ti.types.ndarray(), 
-                  box:ti.types.ndarray(),
-                  boundary:ti.types.ndarray(), 
+                  verlet_list:ti.types.ndarray(),  
                   loop_index:ti.types.ndarray(), 
                   csp:ti.types.ndarray()):
 
         # Get loop index
         num = 0
         ti.loop_config(serialize=True)
         for i in range(self.N):
@@ -96,93 +108,95 @@
                 num += 1
     
         for i, index in ti.ndrange(pair.shape[0], pair.shape[1]):
             j = loop_index[index, 0]
             k = loop_index[index, 1]
             rij = pos[verlet_list[i, j]] - pos[i]
             rik = pos[verlet_list[i, k]] - pos[i]
-            rij = self._pbc(rij, box, boundary)
-            rik = self._pbc(rik, box, boundary)
+            rij = self._pbc(rij)
+            rik = self._pbc(rik)
             pair[i, index] = (rij+rik).norm_sqr()
 
         # Select sort
         for i in range(pair.shape[0]):
+            res = ti.f64(0.)
             for j in range(int(self.N/2)):
                 minIndex = j
                 for k in range(j+1, pair.shape[1]):
                     if pair[i, k] < pair[i, minIndex]:
                         minIndex = k
                 if minIndex != j:
                     pair[i, minIndex], pair[i, j] = pair[i, j], pair[i, minIndex]
-                csp[i] += pair[i, j]
+                res += pair[i, j]
+            csp[i] = res
         
     def compute(self):
         """Do the real CSP calculation.
         """
         assert self.pos.shape[0] > self.N 
 
         verlet_list = self.verlet_list
         if verlet_list is None:
             kdt = kdtree(self.pos, self.box, self.boundary)
             _, verlet_list = kdt.query_nearest_neighbors(self.N)
         loop_index = np.zeros((int(self.N*(self.N-1)/2), 2), dtype=int)
         pair = np.zeros((self.pos.shape[0], int(self.N*(self.N-1)/2)))
         self.csp = np.zeros(self.pos.shape[0])
-        self._get_csp(pair, self.pos, verlet_list, self.box, self.boundary, loop_index, self.csp)
+        self._get_csp(pair, self.pos, verlet_list, loop_index, self.csp)
 
 
 if __name__ == '__main__':
     from lattice_maker import LatticeMaker
     from neighbor import Neighbor
     from time import time
-    ti.init(ti.gpu, device_memory_GB=5.0)
-    #ti.init(ti.cpu)
+    # ti.init(ti.gpu, device_memory_GB=5.0)
+    ti.init(ti.cpu)
     start = time()
     lattice_constant = 4.05
-    x, y, z = 100, 100, 100
+    x, y, z = 100, 100, 250
     FCC = LatticeMaker(lattice_constant, "FCC", x, y, z)
     FCC.compute()
     end = time()
     print(f"Build {FCC.pos.shape[0]} atoms FCC time: {end-start} s.")
 
-    # Neigh = Neighbor(FCC.pos, FCC.box, 4.05, max_neigh=30)
-    # Neigh.compute()
-    # print(Neigh.neighbor_number.min())
+    Neigh = Neighbor(FCC.pos, FCC.box, 4.05, max_neigh=30)
+    Neigh.compute()
+    print(Neigh.neighbor_number.min())
 
     # start = time()
     # verlet_list_sort = np.ascontiguousarray(np.take_along_axis(Neigh.verlet_list, np.argpartition(Neigh.distance_list, 12, axis=-1), axis=-1)[:, :12])
     # end = time()
     # print(f'numpy sort time: {end-start} s.')
     # print(verlet_list_sort[0])
 
-    # start = time()
-    # Neigh.sort_verlet_by_distance(12)
-    # end = time()
-    # print(f'taichi sort time: {end-start} s.')
-    # print(Neigh.verlet_list[0, :12])
-    # print(Neigh.distance_list[0, :12])
+    start = time()
+    Neigh.sort_verlet_by_distance(12)
+    end = time()
+    print(f'taichi sort time: {end-start} s.')
+    print(Neigh.verlet_list[0, :12])
+    print(Neigh.distance_list[0, :12])
 
     # start = time()
     # kdt = kdtree(FCC.pos, FCC.box, [1, 1, 1])
     # _, verlet_list_kdt = kdt.query_nearest_neighbors(12)
     # end = time()
     # print(f'kdt time: {end-start} s.')
     # print(verlet_list_kdt[0])
 
-    # start = time()
-    # CSP = CentroSymmetryParameter(12, FCC.pos, FCC.box, [1, 1, 1])
-    # CSP.compute()
-    # csp = CSP.csp 
-    # end = time()
-    # print(f"Cal csp kdt time: {end-start} s.")
-    # print(csp[:10])
-    # print(csp.min(), csp.max(), csp.mean())
-
     start = time()
     CSP = CentroSymmetryParameter(12, FCC.pos, FCC.box, [1, 1, 1])
     CSP.compute()
     csp = CSP.csp 
     end = time()
+    print(f"Cal csp kdt time: {end-start} s.")
+    print(csp[:10])
+    print(csp.min(), csp.max(), csp.mean())
+
+    start = time()
+    CSP = CentroSymmetryParameter(12, FCC.pos, FCC.box, [1, 1, 1], verlet_list=Neigh.verlet_list)
+    CSP.compute()
+    csp = CSP.csp 
+    end = time()
     print(f"Cal csp verlet time: {end-start} s.")
     print(csp[:10])
     print(csp.min(), csp.max(), csp.mean())
```

## mdapy/cluser_analysis.py

```diff
@@ -50,25 +50,24 @@
         >>> Clus.particleClusters # Check atom in which cluster.
 
         >>> Clus.get_size_of_cluster(1) # Obtain the atom number in cluster 1.
 
     """
 
     def __init__(self, rc, verlet_list, distance_list):
-
         self.rc = rc
         self.verlet_list = verlet_list
         self.distance_list = distance_list
         self.is_computed = False
 
     def compute(self):
         """Do the real cluster analysis."""
         N = self.verlet_list.shape[0]
         self.particleClusters = np.zeros(N, dtype=np.int32) - 1
-        self.cluster_number = _cluster_analysis.get_cluster(
+        self.cluster_number = _cluster_analysis._get_cluster(
             self.verlet_list, self.distance_list, self.rc, self.particleClusters
         )
         # print(f"Cluster number is {self.cluster_number}.")
         self.is_computed = True
 
     def get_size_of_cluster(self, cluster_id):
         """This method can obtain the number of atoms in cluster :math:`cluster\_id`.
```

## mdapy/create_polycrystalline.py

```diff
@@ -3,21 +3,22 @@
 
 from time import time
 import numpy as np
 import taichi as ti
 import pandas as pd
 import pyarrow as pa
 from pyarrow import csv
+import multiprocessing as mt
 
 if __name__ == "__main__":
-    from polygon import _poly
+    from voronoi import _voronoi_analysis
     from lattice_maker import LatticeMaker
     from neighbor import Neighbor
 else:
-    import _poly
+    import _voronoi_analysis
     from .lattice_maker import LatticeMaker
     from .neighbor import Neighbor
 
 
 class Cell:
     def __init__(
         self, face_vertices, vertices, volume, cavity_radius, face_areas, pos
@@ -42,25 +43,28 @@
         return self._volume
 
     def cavity_radius(self):
         return self._cavity_radius
 
 
 class Container(list):
-    def __init__(self, pos, box, boundary) -> None:
+    def __init__(self, pos, box, boundary, num_t) -> None:
         self.pos = pos
         self.box = box
         self.boundary = np.bool_(boundary)
+        self.num_t = num_t
         (
             face_vertices,
             vertices,
             volume,
             cavity_radius,
             face_areas,
-        ) = _poly.get_cell_info(self.pos, self.box, self.boundary)
+        ) = _voronoi_analysis.get_cell_info(
+            self.pos, self.box, self.boundary, self.num_t
+        )
         for i in range(self.pos.shape[0]):
             self.append(
                 Cell(
                     face_vertices[i],
                     vertices[i],
                     volume[i],
                     cavity_radius[i],
@@ -89,14 +93,15 @@
         metal_gra_overlap_dis (float, optional): minimum distance between metallic particles and graphene. Defaults to 3.1.
         gra_overlap_dis (float, optional): minimum distance between atoms in graphene. Defaults to 1.2.
         seed (np.ndarray, optional): (seednumber, 3) initial position of seed to generate Voronoi polygon. If not given, it will be generated by the given randomseed.
         if_rotation (bool, optional): whether rotate the grain orientation. Defaults to True.
         theta_list (np.ndarray, optional): (seednumber, 3) rotation degree of each grain along x, y, z axis. If not given, it will be generated by the given randomseed.
         face_threshold (float, optional): minimum voronoi polygon face area to add graphene. Defaults to 5.0.
         output_name (str, optional): filename of DUMP file. Defaults to None.
+        num_t (int, optional): threads number to generate Voronoi diagram. If not given, use all avilable threads.
 
     Outputs:
         - **generate an polycrystalline DUMP file with grain ID.**
 
     Examples:
         >>> import mdapy as mp
 
@@ -123,16 +128,16 @@
         metal_gra_overlap_dis=3.1,
         gra_overlap_dis=1.2,
         seed=None,
         if_rotation=True,
         theta_list=None,
         face_threshold=5.0,
         output_name=None,
+        num_t=None,
     ) -> None:
-
         self._real_box = np.array(box, float)
         self._lower = self._real_box[:, 0]
         self.box = np.c_[np.zeros(3), self._real_box[:, 1] - self._real_box[:, 0]]
         self.seednumber = seednumber
         self.metal_latttice_constant = metal_latttice_constant
         self.metal_lattice_type = metal_lattice_type
         assert self.metal_lattice_type in [
@@ -185,14 +190,20 @@
             if self.add_graphene:
                 self.output_name = f"GRA-Metal-{self.metal_lattice_type}-{self.seednumber}-{self.randomseed}.dump"
             else:
                 self.output_name = f"Metal-{self.metal_lattice_type}-{self.seednumber}-{self.randomseed}.dump"
         else:
             self.output_name = output_name
 
+        if num_t is None:
+            self.num_t = mt.cpu_count()
+        else:
+            assert num_t >= 1, "num_t should be a positive integer!"
+            self.num_t = int(num_t)
+
     @ti.func
     def _get_plane_equation_coeff(self, p1, p2, p3, coeff):
         """Get plane equation parameters from three points in plane.
         :math:`ax+by+cz+d=0`
 
         Args:
             p1 (ti.types.ndarray): (3 * 1) point 1 in plane.
@@ -531,15 +542,15 @@
             write_options = csv.WriteOptions(delimiter=" ", include_header=False)
             csv.write_csv(table, op, write_options=write_options)
 
     def compute(self):
         """Do the real polycrystalline structure building."""
         start = time()
         print("Generating voronoi polygon...")
-        self.cntr = Container(self.seed, self.box, [1, 1, 1])
+        self.cntr = Container(self.seed, self.box, [1, 1, 1], self.num_t)
         ave_grain_volume = np.mean([cell.volume() for cell in self.cntr])
         new_pos = self._get_pos()
         print("Wraping atoms into box...")
         self._wrap_pos(new_pos, self.box)
         print("Deleting overlap atoms...")
         if self.add_graphene:
             neigh = Neighbor(
@@ -607,15 +618,14 @@
         print("Saving atoms into dump file...")
         self._write_dump(new_pos)
         end = time()
         print(f"Time costs: {end-start} s.")
 
 
 if __name__ == "__main__":
-
     # box = np.array([[0.0, 100], [0.0, 100.0], [0.0, 100.0]])
     # seed = np.random.rand(20, 3) * (box[:, 1] - box[:, 0])
     # boundary = [1, 1, 1]
     # cntr = Container(seed, box, boundary)
     # cell = cntr[0]
     # print("r:", cell.cavity_radius())
     # print("volume:", cell.volume())
@@ -627,16 +637,16 @@
     # for i in cntr:
     #     print(i)
     # print(cntr[0].cavity_radius())
     # print(cntr[:1])
     # print(len(cntr))
     # print(cntr[0].face_vertices())
     # # print(cntr[0].vertices())
-    # ti.init(ti.cpu)
-    # box = np.array([[-100, 100], [-100, 100], [-100, 100]])
-    # # polycry = CreatePolycrystalline(box, 20, 3.615, "FCC")
-    # # polycry.compute()
-    # polycry = CreatePolycrystalline(
-    #     box, 10, 2.615, "FCC", add_graphene=True, if_rotation=True
-    # )
+    ti.init(ti.cpu)
+    box = np.array([[-100, 100], [-100, 100], [-100, 100]])
+    # polycry = CreatePolycrystalline(box, 20, 3.615, "FCC")
     # polycry.compute()
+    polycry = CreatePolycrystalline(
+        box, 10, 2.615, "FCC", add_graphene=True, if_rotation=True
+    )
+    polycry.compute()
     print("test")
```

## mdapy/system.py

```diff
@@ -2,17 +2,17 @@
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 from pyarrow import csv
+import multiprocessing as mt
 
 if __name__ == "__main__":
-
     from ackland_jones_analysis import AcklandJonesAnalysis
     from common_neighbor_analysis import CommonNeighborAnalysis
     from common_neighbor_parameter import CommonNeighborParameter
     from neighbor import Neighbor
     from temperature import AtomicTemperature
     from centro_symmetry_parameter import CentroSymmetryParameter
     from entropy import AtomicEntropy
@@ -25,14 +25,15 @@
     from void_distribution import VoidDistribution
     from warren_cowley_parameter import WarrenCowleyParameter
     from voronoi_analysis import VoronoiAnalysis
     from mean_squared_displacement import MeanSquaredDisplacement
     from lindemann_parameter import LindemannParameter
     from spatial_binning import SpatialBinning
     from steinhardt_bond_orientation import SteinhardtBondOrientation
+    from replicate import Replicate
 else:
     from .common_neighbor_analysis import CommonNeighborAnalysis
     from .ackland_jones_analysis import AcklandJonesAnalysis
     from .common_neighbor_parameter import CommonNeighborParameter
     from .neighbor import Neighbor
     from .temperature import AtomicTemperature
     from .centro_symmetry_parameter import CentroSymmetryParameter
@@ -46,14 +47,15 @@
     from .void_distribution import VoidDistribution
     from .warren_cowley_parameter import WarrenCowleyParameter
     from .voronoi_analysis import VoronoiAnalysis
     from .mean_squared_displacement import MeanSquaredDisplacement
     from .lindemann_parameter import LindemannParameter
     from .spatial_binning import SpatialBinning
     from .steinhardt_bond_orientation import SteinhardtBondOrientation
+    from .replicate import Replicate
 
 
 @ti.kernel
 def _wrap_pos(
     pos: ti.types.ndarray(), box: ti.types.ndarray(), boundary: ti.types.ndarray()
 ):
     """This function is used to wrap particle positions into box considering periodic boundarys.
@@ -267,15 +269,14 @@
         self.data_head = None
         self.data_format = data_format
         self.amass = amass
         self.if_neigh = False
         self.filename = filename
         self.sorted_id = sorted_id
         if filename is None:
-
             self.format = format
             self.box = box
             self.pos = pos
             self.N = self.pos.shape[0]
             self.boundary = boundary
             self.vel = vel
             if type_list is None:
@@ -299,15 +300,14 @@
                 # self.data[["id", "type", "q", "x", "y", "z"]] = self.data[["id", "type", "x", "y", "z", "q"]]
                 self.data.insert(2, "q", self.q)
             if not self.vel is None:
                 self.data[["vx", "vy", "vz"]] = self.vel
             self.data[["id", "type"]] = self.data[["id", "type"]].astype(int)
             self.Ntype = len(np.unique(self.data["type"]))
         else:
-
             if format is None:
                 self.format = self.filename.split(".")[-1]
             else:
                 self.format = format
             assert self.format in [
                 "data",
                 "dump",
@@ -319,144 +319,148 @@
                 self.data_format = None
             self.N = self.pos.shape[0]
 
         self.lx, self.ly, self.lz = self.box[:, 1] - self.box[:, 0]
         self.vol = self.lx * self.ly * self.lz
         self.rho = self.N / self.vol
 
+    def __repr__(self):
+        return f"A System with {self.N} atoms."
+
     def _read_data(self):
         self.data_head = []
         self.box = np.zeros((3, 2))
-
-        with open(self.filename) as op:
-            file = op.readlines()
-
         row = 0
         mass_row = 0
-        for line in file:
-
-            self.data_head.append(line)
-            content = line.split()
-            if len(content):
-                if content[-1] == "atoms":
-                    self.N = int(content[0])
-                if len(content) >= 2:
-                    if content[1] == "bond":
-                        raise "Do not support bond style."
-                if len(content) >= 3:
-                    if content[1] == "atom" and content[2] == "types":
-                        self.Ntype = int(content[0])
-                if content[-1] == "xhi":
-                    self.box[0, :] = np.array([content[0], content[1]], dtype=float)
-                if content[-1] == "yhi":
-                    self.box[1, :] = np.array([content[0], content[1]], dtype=float)
-                if content[-1] == "zhi":
-                    self.box[2, :] = np.array([content[0], content[1]], dtype=float)
-                if content[-1] in ["xy", "xz", "yz"]:
-                    raise "Do not support triclinic box."
-                if content[0] == "Masses":
-                    mass_row = row + 1
-                if content[0] == "Atoms":
-                    break
-            row += 1
+        with open(self.filename) as op:
+            while True:
+                line = op.readline()
+                self.data_head.append(line)
+                content = line.split()
+                if len(content):
+                    if content[-1] == "atoms":
+                        self.N = int(content[0])
+                    if len(content) >= 2:
+                        if content[1] == "bond":
+                            raise "Do not support bond style."
+                    if len(content) >= 3:
+                        if content[1] == "atom" and content[2] == "types":
+                            self.Ntype = int(content[0])
+                    if content[-1] == "xhi":
+                        self.box[0, :] = np.array([content[0], content[1]], dtype=float)
+                    if content[-1] == "yhi":
+                        self.box[1, :] = np.array([content[0], content[1]], dtype=float)
+                    if content[-1] == "zhi":
+                        self.box[2, :] = np.array([content[0], content[1]], dtype=float)
+                    if content[-1] in ["xy", "xz", "yz"]:
+                        raise "Do not support triclinic box."
+                    if content[0] == "Masses":
+                        mass_row = row + 1
+                    if content[0] == "Atoms":
+                        break
+                row += 1
         if mass_row > 0:
             self.amass = np.array(
                 [
                     i.split()[:2]
                     for i in self.data_head[mass_row + 1 : mass_row + 1 + self.Ntype]
                 ],
                 dtype=float,
             )[:, 1]
         self.boundary = [1, 1, 1]
 
+        row += 2  # Coordination part
         if self.data_head[-1].split()[-1] == "atomic":
             self.data_format = "atomic"
             self.col_names = ["id", "type", "x", "y", "z"]
         elif self.data_head[-1].split()[-1] == "charge":
             self.data_format = "charge"
             self.col_names = ["id", "type", "q", "x", "y", "z"]
         else:
-            if len(file[row + 2].split()) == 5:
+            with open(self.filename) as op:
+                for _ in range(row):
+                    op.readline()
+                line = op.readline()
+            if len(line.split()) == 5:
                 self.data_format = "atomic"
                 self.col_names = ["id", "type", "x", "y", "z"]
-            elif len(file[row + 2].split()) == 6:
+            elif len(line.split()) == 6:
                 self.data_format = "charge"
                 self.col_names = ["id", "type", "q", "x", "y", "z"]
             else:
                 raise "Unrecgonized data format. Only support atomic and charge."
 
-        data = np.array(
-            [i.split() for i in file[row + 2 : row + 2 + self.N]], dtype=float
-        )[:, : len(self.col_names)]
-        row += 2 + self.N
-        if_vel = False
-        if row < len(file):
-            for line in file[row:]:
-                content = line.split()
-                if len(content):
-                    if content[0] == "Velocities":
-                        if_vel = True
-                        break
-                row += 1
-            if if_vel:
-                vel = np.array(
-                    [i.split() for i in file[row + 2 : row + 2 + self.N]], dtype=float
-                )[:, 1:]
-                self.col_names += ["vx", "vy", "vz"]
-                self.data = pd.DataFrame(np.c_[data, vel], columns=self.col_names)
-        else:
-            self.data = pd.DataFrame(data, columns=self.col_names)
+        data = pd.read_csv(
+            self.filename,
+            sep=" ",
+            skiprows=row,
+            nrows=self.N,
+            names=self.col_names,
+            usecols=range(len(self.col_names)),
+            engine="c",
+        )
+
+        row += self.N
+        try:
+            read_options = csv.ReadOptions(
+                column_names=["id", "vx", "vy", "vz"], skip_rows_after_names=row + 3
+            )
+            parse_options = csv.ParseOptions(delimiter=" ")
+            vel = (
+                csv.read_csv(
+                    self.filename,
+                    read_options=read_options,
+                    parse_options=parse_options,
+                )
+                .drop(["id"])
+                .to_pandas()
+            )
+            self.col_names += ["vx", "vy", "vz"]
+            self.data = pd.concat([data, vel], axis=1)
+            self.vel = vel.values
+        except Exception:
+            self.data = data
 
         if self.sorted_id:
             self.data.sort_values("id", inplace=True)
-        self.data[["id", "type"]] = self.data[["id", "type"]].astype(int)
         self.pos = self.data[["x", "y", "z"]].values
-        if if_vel:
-            self.vel = self.data[["vx", "vy", "vz"]].values
 
     def _read_dump(self):
         self.dump_head = []
         if_space = False
         with open(self.filename) as op:
             for i in range(10):
                 if i < 9:
                     self.dump_head.append(op.readline())
                 else:
                     if op.readline()[-2] == " ":
                         if_space = True
         self.boundary = [1 if i == "pp" else 0 for i in self.dump_head[4].split()[-3:]]
         self.box = np.array([i.split()[:2] for i in self.dump_head[5:8]]).astype(float)
         self.col_names = self.dump_head[8].split()[2:]
-        try:
-            if if_space:
-                data = pd.read_csv(
-                    self.filename,
-                    skiprows=9,
-                    sep=" ",
-                    names=self.col_names + ["drop"],
-                    engine="pyarrow",
-                )
-                del data["drop"]
-                self.data = data
-            else:
-                self.data = pd.read_csv(
+        if if_space:
+            read_options = csv.ReadOptions(
+                column_names=self.col_names + ["drop"], skip_rows=9
+            )
+            parse_options = csv.ParseOptions(delimiter=" ")
+            self.data = (
+                csv.read_csv(
                     self.filename,
-                    skiprows=9,
-                    sep=" ",
-                    names=self.col_names,
-                    engine="pyarrow",
+                    read_options=read_options,
+                    parse_options=parse_options,
                 )
-        except Exception:
-            self.data = pd.read_csv(
-                self.filename,
-                skiprows=9,
-                index_col=False,
-                sep=" ",
-                names=self.col_names,
+                .drop(["drop"])
+                .to_pandas()
             )
+        else:
+            read_options = csv.ReadOptions(column_names=self.col_names, skip_rows=9)
+            parse_options = csv.ParseOptions(delimiter=" ")
+            self.data = csv.read_csv(
+                self.filename, read_options=read_options, parse_options=parse_options
+            ).to_pandas()
 
         if self.sorted_id:
             self.data.sort_values("id", inplace=True)
         self.pos = self.data[["x", "y", "z"]].values
         self.Ntype = len(np.unique(self.data["type"]))
         try:
             self.vel = self.data[["vx", "vy", "vz"]].values
@@ -528,73 +532,52 @@
 
         if output_name is None:
             if self.filename is None:
                 output_name = "output.data"
             else:
                 output_name = self.filename[:-4] + "output.data"
 
-        with open(output_name, "w") as op:
+        with pa.OSFile(output_name, "wb") as op:
             if self.data_head is None:
-                op.write("# LAMMPS data file written by mdapy@HerrWu.\n\n")
-                op.write(f"{data.shape[0]} atoms\n{self.Ntype} atom types\n\n")
+                op.write("# LAMMPS data file written by mdapy@HerrWu.\n\n".encode())
+                op.write(f"{data.shape[0]} atoms\n{self.Ntype} atom types\n\n".encode())
                 for i, j in zip(self.box, ["x", "y", "z"]):
-                    op.write(f"{i[0]} {i[1]} {j}lo {j}hi\n")
-                op.write("\n")
+                    op.write(f"{i[0]} {i[1]} {j}lo {j}hi\n".encode())
+                op.write("\n".encode())
                 if not self.amass is None:
-                    op.write("Masses\n\n")
+                    op.write("Masses\n\n".encode())
                     for i in range(self.Ntype):
-                        op.write(f"{i+1} {self.amass[i]}\n")
-                    op.write("\n")
-                op.write(rf"Atoms # {data_format}")
-                op.write("\n\n")
+                        op.write(f"{i+1} {self.amass[i]}\n".encode())
+                    op.write("\n".encode())
+                op.write(rf"Atoms # {data_format}".encode())
+                op.write("\n\n".encode())
             else:
                 self.data_head[-1] = f"Atoms # {data_format}\n"
-                op.write("# LAMMPS data file written by mdapy@HerrWu.\n")
-                op.write("".join(self.data_head[1:]))
-                op.write("\n")
-        if data_format == "atomic":
-            self.data[["id", "type", "x", "y", "z"]].to_csv(
-                output_name, header=None, index=False, sep=" ", mode="a", na_rep="nan"
-            )
-        elif data_format == "charge":
-            if "q" not in self.data.columns:
-                self.data.insert(2, "q", np.zeros(self.N))
-                self.data[["id", "type", "q", "x", "y", "z"]].to_csv(
-                    output_name,
-                    header=None,
-                    index=False,
-                    sep=" ",
-                    mode="a",
-                    na_rep="nan",
-                )
-                self.data.drop("q", axis=1, inplace=True)
-            else:
-                self.data[["id", "type", "q", "x", "y", "z"]].to_csv(
-                    output_name,
-                    header=None,
-                    index=False,
-                    sep=" ",
-                    mode="a",
-                    na_rep="nan",
-                )
-        try:
-            if len(self.vel):
-                with open(output_name, "a") as op:
-                    op.write("\nVelocities\n\n")
-                data[["id", "vx", "vy", "vz"]].to_csv(
-                    output_name,
-                    header=None,
-                    index=False,
-                    sep=" ",
-                    mode="a",
-                    na_rep="nan",
-                )
-        except Exception:
-            # print("No velocities provided!")
-            pass
+                op.write("# LAMMPS data file written by mdapy@HerrWu.\n".encode())
+                op.write("".join(self.data_head[1:]).encode())
+                op.write("\n".encode())
+            write_options = csv.WriteOptions(delimiter=" ", include_header=False)
+            if data_format == "atomic":
+                table = pa.Table.from_pandas(data[["id", "type", "x", "y", "z"]])
+                csv.write_csv(table, op, write_options=write_options)
+            elif data_format == "charge":
+                if "q" not in self.data.columns:
+                    table = pa.Table.from_pandas(data[["id", "type", "x", "y", "z"]])
+                    table.add_column(2, "q", pa.array(np.zeros(self.N)))
+                    csv.write_csv(table, op, write_options=write_options)
+                else:
+                    table = pa.Table.from_pandas(
+                        data[["id", "type", "q", "x", "y", "z"]]
+                    )
+                    csv.write_csv(table, op, write_options=write_options)
+
+            if "vx" in data.columns:
+                op.write("\nVelocities\n\n".encode())
+                table = pa.Table.from_pandas(data[["id", "vx", "vy", "vz"]])
+                csv.write_csv(table, op, write_options=write_options)
 
     def atom_distance(self, i, j):
         """Calculate the distance fo atom :math:`i` and atom :math:`j` considering the periodic boundary.
 
         Args:
             i (int): atom :math:`i`.
             j (int): atom :math:`j`.
@@ -612,14 +595,62 @@
     def wrap_pos(self):
         """Wrap atom position into box considering the periodic boundary."""
         pos = self.pos.copy()  # a deep copy can be modified
         _wrap_pos(pos, self.box, np.array(self.boundary))
         self.pos = pos
         self.data[["x", "y", "z"]] = self.pos
 
+    def replicate(self, x=1, y=1, z=1):
+        """Replicate the system.
+
+        Args:
+            x (int, optional): replication number (positive integer) along x axis. Defaults to 1.
+            y (int, optional): replication number (positive integer) along y axis. Defaults to 1.
+            z (int, optional): replication number (positive integer) along z axis. Defaults to 1.
+        """
+        assert x > 0 and isinstance(x, int), "x should be a positive integer."
+        assert y > 0 and isinstance(y, int), "y should be a positive integer."
+        assert z > 0 and isinstance(z, int), "z should be a positive integer."
+
+        repli = Replicate(self.pos, self.box, x, y, z)
+        repli.compute()
+        num = x * y * z
+        id_list = self.data["id"].values
+        self.data = pd.concat([self.data] * num, ignore_index=True)
+        self.data["id"] = np.array([id_list + i * self.N for i in range(num)]).flatten()
+
+        self.data[["x", "y", "z"]] = repli.pos
+        self.N = self.data.shape[0]
+        self.box = repli.box.copy()
+        self.pos = self.data[["x", "y", "z"]].values
+        if "vx" in self.data.columns:
+            self.vel = self.data[["vx", "vy", "vz"]].values
+
+        self.lx, self.ly, self.lz = self.box[:, 1] - self.box[:, 0]
+        self.vol = self.lx * self.ly * self.lz
+        self.rho = self.N / self.vol
+        del repli
+        if self.dump_head is not None:
+            self.dump_head[5] = "{} {}\n".format(*self.box[0])
+            self.dump_head[6] = "{} {}\n".format(*self.box[1])
+            self.dump_head[7] = "{} {}\n".format(*self.box[2])
+        if self.data_head is not None:
+            row = 0
+            for i in self.data_head:
+                line = i.split()
+                if len(line) > 0:
+                    if line[-1] == "atoms":
+                        self.data_head[row] = f"{self.N} atoms\n"
+                    if line[-1] == "xhi":
+                        break
+                row += 1
+            self.data_head[row] = "{} {} xlo xhi\n".format(*self.box[0])
+            self.data_head[row + 1] = "{} {} ylo yhi\n".format(*self.box[1])
+            self.data_head[row + 2] = "{} {} zlo zhi\n".format(*self.box[2])
+
     def build_neighbor(self, rc=5.0, max_neigh=80, exclude=True):
         """Build neighbor withing a spherical distance based on the mdapy.Neighbor class.
 
         Args:
             rc (float, optional): cutoff distance. Defaults to 5.0.
             max_neigh (int, optional): maximum number of atom neighbor number. Defaults to 80.
             exclude (bool, optional): whether exclude atom itself. Defaults to True.
@@ -700,15 +731,14 @@
         .. hint:: The module uses the `legacy algorithm in LAMMPS <https://docs.lammps.org/compute_ackland_atom.html>`_.
 
         Outputs:
             - **The result is added in self.data['aja']**.
         """
         use_verlet = False
         if self.if_neigh:
-
             if self.neighbor_number.min() >= 14:
                 _partition_select_sort(self.verlet_list, self.distance_list, 14)
                 AcklandJonesAna = AcklandJonesAnalysis(
                     self.pos,
                     self.box,
                     self.boundary,
                     self.verlet_list,
@@ -1420,26 +1450,35 @@
             neigh.compute()
             self.WarrenCowleyParameter = WarrenCowleyParameter(
                 neigh.verlet_list, neigh.neighbor_number, self.data["type"].values
             )
 
         self.WarrenCowleyParameter.compute()
 
-    def cal_voronoi_volume(self):
+    def cal_voronoi_volume(self, num_t=None):
         """This class is used to calculate the Voronoi polygon, wchich can be applied to
         estimate the atomic volume. The calculation is conducted by the `voro++ <https://math.lbl.gov/voro++/>`_ package and
         this class only provides a wrapper.
 
+        Args:
+            num_t (int, optional): threads number to generate Voronoi diagram. If not given, use all avilable threads.
+
         Outputs:
             - **The atomic Voronoi volume is added in self.data['voronoi_volume']**.
             - **The atomic Voronoi neighbor is added in self.data["voronoi_number"]**.
             - **The atomic Voronoi cavity radius is added in self.data["cavity_radius"]**.
 
         """
-        voro = VoronoiAnalysis(self.pos, self.box, self.boundary)
+        if num_t is None:
+            num_t = mt.cpu_count()
+        else:
+            assert num_t >= 1, "num_t should be a positive integer!"
+            num_t = int(num_t)
+
+        voro = VoronoiAnalysis(self.pos, self.box, self.boundary, num_t)
         voro.compute()
         self.data["voronoi_volume"] = voro.vol
         self.data["voronoi_number"] = voro.neighbor_number
         self.data["cavity_radius"] = voro.cavity_radius
 
     def spatial_binning(self, direction, vbin, wbin=5.0, operation="mean"):
         """This class is used to divide particles into different bins and operating on each bin.
@@ -1481,29 +1520,28 @@
     Outputs:
         - **pos_list** (np.ndarray): (:math:`N_f, N_p, 3`), :math:`N_f` frames particle position.
         - **Nframes** (int): number of frames.
 
     """
 
     def __init__(self, filename_list, unwrap=True, sorted_id=True, image_p=None):
-
         self.sorted_id = sorted_id
         self.unwrap = unwrap
         self.image_p = image_p
         try:
             from tqdm import tqdm
 
             progress_bar = tqdm(filename_list)
             for filename in progress_bar:
                 progress_bar.set_description(f"Reading {filename}")
                 system = System(filename, sorted_id=self.sorted_id)
                 self.append(system)
         except Exception:
             for filename in filename_list:
-                print(f"Reading {filename}", end="")
+                print(f"\rReading {filename}", end="")
                 system = System(filename, sorted_id=self.sorted_id)
                 self.append(system)
 
         self.pos_list = np.array([system.pos for system in self])
         if self.unwrap:
             if self.image_p is None:
                 try:
@@ -1529,15 +1567,15 @@
 
             progress_bar = tqdm(self)
             for system in progress_bar:
                 progress_bar.set_description(f"Saving {system.filename}")
                 system.write_dump(output_col=output_col)
         except Exception:
             for system in self:
-                print(f"Saving {system.filename}", end="")
+                print(f"\rSaving {system.filename}", end="")
                 system.write_dump(output_col=output_col)
 
     def cal_mean_squared_displacement(self, mode="windows"):
         """Calculate the mean squared displacement MSD of system, which can be used to
         reflect the particle diffusion trend and describe the melting process. Generally speaking, MSD is an
         average displacement over all windows of length :math:`m` over the course of the simulation (so-called
         'windows' mode here) and defined by:
@@ -1576,15 +1614,14 @@
 
         self.MSD = MeanSquaredDisplacement(self.pos_list, mode=mode)
         self.MSD.compute()
         for frame in range(self.Nframes):
             self[frame].data["msd"] = self.MSD.particle_msd[frame]
 
     def cal_lindemann_parameter(self, only_global=False):
-
         """
         Calculate the `Lindemann index <https://en.wikipedia.org/wiki/Lindemann_index>`_,
         which is useful to distinguish the melt process and determine the melting points of nano-particles.
         The Lindemann index is defined as the root-mean-square bond-length fluctuation with following mathematical expression:
 
         .. math:: \\left\\langle\\sigma_{i}\\right\\rangle=\\frac{1}{N_{p}(N_{p}-1)} \\sum_{j \\neq i} \\frac{\\sqrt{\\left\\langle r_{i j}^{2}\\right\\rangle_t-\\left\\langle r_{i j}\\right\\rangle_t^{2}}}{\\left\\langle r_{i j}\\right\\rangle_t},
```

## mdapy/voronoi_analysis.py

```diff
@@ -1,11 +1,13 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
+# We highly thanks to Dr. Jiayin Lu for the help on parallelism of this module.
 
 import numpy as np
+import multiprocessing as mt
 
 if __name__ == "__main__":
     from voronoi import _voronoi_analysis
 else:
     import _voronoi_analysis
 
 
@@ -14,14 +16,15 @@
     estimate the atomic volume. The calculation is conducted by the `voro++ <https://math.lbl.gov/voro++/>`_ package and
     this class only provides a wrapper.
 
     Args:
         pos (np.ndarray): (:math:`N_p, 3`) particles positions.
         box (np.ndarray): (:math:`3, 2`) system box.
         boundary (list): boundary conditions, 1 is periodic and 0 is free boundary, such as [1, 1, 1].
+        num_t (int, optional): threads number to generate Voronoi diagram. If not given, use all avilable threads.
 
     Outputs:
         - **vol** (np.ndarray) - (:math:`N_p`), atom Voronoi volume.
         - **neighbor_number** (np.ndarray) - (:math:`N_p`), atom Voronoi neighbor number.
         - **cavity_radius** (np.ndarray) - the distance from the particle to the farthest vertex of its Voronoi cell.
 
     Examples:
@@ -40,45 +43,49 @@
         >>> avol.vol # Check atomic Voronoi volume.
 
         >>> avol.neighbor_number # Check neighbor number.
 
         >>> avol.cavity_radius # Check the cavity radius.
     """
 
-    def __init__(self, pos, box, boundary) -> None:
-
+    def __init__(self, pos, box, boundary, num_t=None) -> None:
         self.pos = pos
         self.box = box
         self.boundary = boundary
+        if num_t is None:
+            self.num_t = mt.cpu_count()
+        else:
+            assert num_t >= 1, "num_t should be a positive integer!"
+            self.num_t = int(num_t)
 
     def compute(self):
         """Do the real Voronoi volume calculation."""
         N = self.pos.shape[0]
         self.vol = np.zeros(N)
         self.neighbor_number = np.zeros(N, dtype=int)
         self.cavity_radius = np.zeros(N)
         _voronoi_analysis.get_voronoi_volume(
             self.pos,
             self.box,
             np.bool_(self.boundary),
             self.vol,
             self.neighbor_number,
             self.cavity_radius,
+            self.num_t,
         )
 
 
 if __name__ == "__main__":
-
     import taichi as ti
     from lattice_maker import LatticeMaker
     from time import time
 
     ti.init()
 
-    FCC = LatticeMaker(4.05, "FCC", 10, 10, 10)  # Create a FCC structure.
+    FCC = LatticeMaker(4.05, "FCC", 100, 100, 50)  # Create a FCC structure.
     FCC.compute()  # Get atom positions.
     # FCC.write_data()
     start = time()
     avol = VoronoiAnalysis(FCC.pos, FCC.box, [1, 1, 1])  # Initilize the Voronoi class.
     avol.compute()  # Calculate the Voronoi volume.
     end = time()
```

## Comparing `mdapy-0.8.5.dist-info/LICENSE` & `mdapy-0.8.6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mdapy-0.8.5.dist-info/METADATA` & `mdapy-0.8.6.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mdapy
-Version: 0.8.5
+Version: 0.8.6
 Summary: A simple, fast and cross-platform python library to handle the data generated from molecular dynamics simulations
 Home-page: https://github.com/mushroomfire/mdapy
 Author: mushroomfire aka HerrWu
 Author-email: yongchao_wu@bit.edu.cn
 License: BSD 3-Clause License
 Project-URL: Homepage, https://github.com/mushroomfire/mdapy
 Project-URL: Documentation, https://mdapy.readthedocs.io/
@@ -191,14 +191,22 @@
 
 .. code-block:: bash
 
    conda install -c conda-forge gxx_linux-64
 
 Release Notes
 --------------
+V0.8.6 (4/22/2023)
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+- Add repr for System class.
+- Add Replicate class.
+- Improve the performance of **reading/writing DATA file with pyarrow**.
+- Improve the performance of **building Voronoi diagram** with new version voro++. 
+
 V0.8.5 (4/9/2023)
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 
 - Compile it on MAC OS with M1. Now **mdapy** is fully cross-platform.
 - Obviously improve the performance of **reading/writing DUMP with pyarrow**.
 - Add **pyarrow** as a dependency package.
 - Fix bug of **create_polycrystalline** module. One can give box with any number, the old version only works for positive float.
```

